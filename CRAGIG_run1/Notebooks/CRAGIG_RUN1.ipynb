{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CRAGIG RUN 1\n",
    "20170202 \n",
    "\n",
    "I got my first batch of RAD data back from BGI, and have yet to really look at it. I'd like to take a first look for population differences, but also I need to help Molly figure out how to build a parentage panel. My first look will be at the **forward reads.**\n",
    "\n",
    "### Download Data from BGI\n",
    "\n",
    "I downloaded the data by clicking on the download FTP button. Downloading each of the two raw data files took about 24 hours, and crashed occasionally. I then moved the two files onto the E drive (which has a ton of space), copied them, and saved on as untouchable. The other, I put in a shared folder so I can play with it in my virtual machine.\n",
    "\n",
    "### Check that Download was Error Free\n",
    "\n",
    "used md5sum, a built in function in Ubuntu, and compared the check sum associated with the raw forward read file and it matched\n",
    "\n",
    "```\n",
    "nclowell@ubuntu:/mnt/hgfs/Data_for_Analysis/WorkingFolder$ md5sum 161228_I137_FCHCYV5BBXX_L5_CHKPE85216120009_1.fq.gz\n",
    "\n",
    "6d7714b6f03d65002894ba5d1c16b520  161228_I137_FCHCYV5BBXX_L5_CHKPE85216120009_1.fq.gz\n",
    "```\n",
    "\n",
    "While I'm' at it, going to check the reverse reads too:\n",
    "\n",
    "\n",
    "### ``process_radtags``\n",
    "\n",
    "``process_radtags`` dumultiplexes your raw data file and (optionally) names the sample by file name. Be sure to include unique file names for any replicates. For example, fg100-fg104, I sequenced twice, each with a unique barcode.\n",
    "\n",
    "\n",
    "[mary says don't use filterillumina; used r c q and trimmed]\n",
    "\n",
    "Stacks [manual page for ``process_radtags``](http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php)\n",
    "\n",
    "Inputs values I will use\n",
    "\n",
    " f — path to the input file if processing single-end seqeunces \n",
    "<br>**-f /mnt/hgfs/Data_for Analysis/WorkingFolder/161228_I137_FCHCYV5BBXX_L5_CHKPE85216120009_1.fq.gz**\n",
    "\n",
    " i — input file type, either 'bustard' for the Illumina BUSTARD format, 'bam', 'fastq' (default), or 'gzfastq' for gzipped FASTQ.\n",
    "<br>**-i gzfastq**\n",
    "\n",
    " y — output type, either 'fastq', 'gzfastq', 'fasta', or 'gzfasta' (default is to match the input file type).\n",
    "<br>**-y gzfastq**\n",
    "\n",
    " o — path to output the processed files.\n",
    "<br>**-o /mnt/hgfs/Data_for Analysis/WorkingFolder/Stacks**\n",
    "\n",
    " t — truncate final read length to this value.\n",
    "<br>**-t 139** (reads are 150 bp, 6 of which are barcode, and trim at least 5, so start with 139. Then run FastQC and see if more trimming is necessary)\n",
    "\n",
    " b — path to a file containing barcodes for this run.\n",
    "<br>**-b /mnt/hgfs/Data_for Analysis/WorkingFolder/barcodes_cragigrun1.txt**\n",
    "\n",
    " r — rescue barcodes and RAD-Tags (this means if barcode is one base off from any barcode you used, Stacks will use some probability function to match to closest barcode and rewrite sequence to reflect that)\n",
    "<br>**-r**\n",
    "\n",
    " c — clean data, remove any read with an uncalled base.\n",
    "<br>**-c**\n",
    "\n",
    " -e [enz], --renz_1 [enz]: provide the restriction enzyme used (cut site occurs on single-end read) <- 'sbfI'\n",
    "<br>**-e sbfI**\n",
    "\n",
    "Your barcode list:\n",
    "\n",
    "Should take the form of barcode \\t samplename \\n\n",
    "\n",
    "Local path for my current barcode list = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Change to appropriate working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Data_for Analysis/WorkingFolder\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/Data_for Analysis/WorkingFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!stacks process_radtags \\\n",
    "-f /mnt/hgfs/Data_for_Analysis/WorkingFolder/161228_I137_FCHCYV5BBXX_L5_CHKPE85216120009_1.fq.gz \\\n",
    "-i gzfastq \\\n",
    "-y gzfastq \\\n",
    "-o /mnt/hgfs/Data_for_Analysis/WorkingFolder/Stacks \\\n",
    "-t 139 \\\n",
    "-b /mnt/hgfs/Data_for_Analysis/WorkingFolder/barcodes_cragigrun1.txt \\\n",
    "-r \\\n",
    "-c \\\n",
    "-e sbfI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**``process_radtags`` output:**\n",
    "\n",
    "387289855 total sequences;\n",
    "  64147742 ambiguous barcode drops;\n",
    "  401015 low quality read drops;\n",
    "  42895231 ambiguous RAD-Tag drops;\n",
    "279845867 retained reads.\n",
    "\n",
    "So 72.26% reads retained.\n",
    "\n",
    "Then, I ran a script to count reads in each post-``process_radtags`` file, which Steven gave to Mary who gave to me. Here's the script. A similar version is on her github, [here](https://github.com/mfisher5/mf-fish546-PCod/blob/master/scripts/L1L2_seqCountsgen.py).\n",
    "\n",
    "```\n",
    "import sys\n",
    "lane1 = open(sys.argv[1], \"r\")\n",
    "newshell = open(\"CountFASTQseqs.sh\", \"w\")\n",
    "\n",
    "newshell.write(\"#!/bin/bash\" + \"\\n\\n\")\n",
    "\n",
    "for line in lane1:\n",
    "\tlinelist = line.strip().split()\n",
    "\tfilestring = \"zcat L1L2samples/\" + linelist[0] + \".fq.gz | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}' >> FastQsequenceCounts.txt\"\n",
    "\tnewshell.write(filestring + \"\\n\")\n",
    "lane1.close()\n",
    "newshell.close()\n",
    "```\n",
    "\n",
    "I'm still working on getting ``matplotlib`` installed in my virtual machine, but until then, I exported the results to excel, sorted, and picked the ten samples with the most reads out of each population. For Alaska"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Quality check with FastQC\n",
    "\n",
    "Looked at several individual sample FastQC reports and they all look great. Mean average quality score of 40, with little variation, and none dropped below the green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ``ustacks``\n",
    "\n",
    "I used a python script I wrote previously to build the shell script. There was an error where it skipped the first few of my samples and didn't run ``ustacks`` on them, so I need to improve it. Also it would be great to be able to input the different parameters with flags. And my brother showed me a module that helps you do that... so I'm going to try to do that now.\n",
    "\n",
    "Example command to show parameter values:\n",
    "\n",
    "``stacks ustacks -t gzfastq -f ./Stacks/Q334.fq.gz -r -d -o ./Stacks -i 001 -m 10 -M 3 -p 10``\n",
    "\n",
    "\n",
    "Only one sample retained few loci (FG100_A retained only 6) so I'm going to exclude that one from further analyses. All of the rest of the samples had at least 20K, with the vast majority around 25K-30K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pick samples for ``cstacks``\n",
    "\n",
    "I just got clarified from lab mates that we're supposed to use the 10 most sequenced individuals from **each** population. I don't even have 10 from each in this run, so I'll include up to 10 from each population.\n",
    "\n",
    "Sorting my Excel sheet to determine these...\n",
    "\n",
    "These leads me to:\n",
    "Q324\n",
    "Q318\n",
    "Q326\n",
    "Q314\n",
    "Q316\n",
    "Q323\n",
    "Q325\n",
    "Q351\n",
    "Q352\n",
    "Q332\n",
    "Q339\n",
    "Q334\n",
    "Q347\n",
    "Q356\n",
    "Q330\n",
    "Q355\n",
    "Q354\n",
    "FG009\n",
    "FG033\n",
    "FG002\n",
    "FG027\n",
    "FG021\n",
    "FG013\n",
    "FG001\n",
    "FG005\n",
    "FG014\n",
    "FG006\n",
    "FG101_A\n",
    "FG102_A\n",
    "FG100_B\n",
    "FG106\n",
    "FG107\n",
    "FG109\n",
    "FG104_A\n",
    "FG111\n",
    "FG108\n",
    "FG103_A\n",
    "FG210\n",
    "FG205\n",
    "FG211\n",
    "FG212\n",
    "FG201\n",
    "FG209\n",
    "FG206\n",
    "FG204\n",
    "FG202\n",
    "FG203\n",
    "\n",
    "\n",
    "<br><br> There are 47 because the AK population only had 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ``cstacks``\n",
    "\n",
    "\n",
    "Now I need to write the ``cstacks`` shell script to run the program on these ten samples. I used my ``easy_cstacks.py`` script.\n",
    "\n",
    "Code for ``cstacks`` was:\n",
    "\n",
    "```\n",
    "stacks cstacks -b 100 -s Stacks/Q324 -s Stacks/Q318 -s Stacks/Q326 -s Stacks/Q314 -s Stacks/Q316 -s Stacks/Q323 -s Stacks/Q325 -s Stacks/Q351 -s Stacks/Q352 -s Stacks/Q332 -s Stacks/Q339 -s Stacks/Q334 -s Stacks/Q347 -s Stacks/Q356 -s Stacks/Q330 -s Stacks/Q355 -s Stacks/Q354 -s Stacks/FG009 -s Stacks/FG033 -s Stacks/FG002 -s Stacks/FG027 -s Stacks/FG021 -s Stacks/FG013 -s Stacks/FG001 -s Stacks/FG005 -s Stacks/FG014 -s Stacks/FG006 -s Stacks/FG101_A -s Stacks/FG102_A -s Stacks/FG100_B -s Stacks/FG106 -s Stacks/FG107 -s Stacks/FG109 -s Stacks/FG104_A -s Stacks/FG111 -s Stacks/FG108 -s Stacks/FG103_A -s Stacks/FG210 -s Stacks/FG205 -s Stacks/FG211 -s Stacks/FG212 -s Stacks/FG201 -s Stacks/FG209 -s Stacks/FG206 -s Stacks/FG204 -s Stacks/FG202 -s Stacks/FG203 -o Stacks -n 3 -p 3 \n",
    "\n",
    "```\n",
    "Worked! And it took ~6.5 hours to run.\n",
    "\n",
    "```\n",
    "Writing catalog to 'Stacks/... done.\n",
    "\n",
    "Running cstacks took \n",
    "06:27:18.40\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ``sstacks``\n",
    "\n",
    "Need to get all the way through populations in order to form catalog of loci for Bowtie and Blast filtering that will then feed back into the Stacks pipeline starting at ``pstacks``.\n",
    "\n",
    "I wrote a script that makes the ``sstacks`` shell, and runs it. Going to update it and run it. \n",
    "\n",
    "The shell script looks like this:\n",
    "\n",
    "```\n",
    "stacks sstacks -b 100 -s Stacks/Q351 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q352 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q332 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q339 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q334 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q347 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q356 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q330 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q355 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q354 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q338 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q353 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q324 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q318 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q326 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q314 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q316 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q323 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/Q325 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG009 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG033 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG002 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG027 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG021 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG013 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG001 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG005 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG014 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG006 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG004 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG024 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG017 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG003 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG018 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG019 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG016 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG015 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG031 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG032 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG007 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG026 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG011 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG035 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG034 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG010 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG101_A -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG102_A -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG100_B -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG106 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG101_B -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG107 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG109 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG102_B -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG104_A -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG111 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG108 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG103_A -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG103_B -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG104_B -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG100_A -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG210 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG205 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG211 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG212 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG201 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG209 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG206 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG204 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG202 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG203 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "stacks sstacks -b 100 -s Stacks/FG207 -o Stacks/ -p 3 -c Stacks/batch_100 \n",
    "\n",
    "```\n",
    "\n",
    "It worked! And it took 00:13:10.65 to run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Populations\n",
    "\n",
    "#### Question: \n",
    "How should my parameter sets compare between the first round of ``populations`` (to build reference genome) and the second round of ``populations`` when I'm actually comparing populations for popgen?\n",
    "\n",
    "Just talked to Dan, who recommended that I be pretty lenient the first time through, and then very stringent (for Molly's parentage panel needs) the second time through. For lenient, he said an r of 0.25 and for p, about half of the number of populations.\n",
    "\n",
    "Code for this run:\n",
    "\n",
    "```\n",
    "stacks populations -b 100 -P Stacks -M popmap_cragigrun1.txt -t 10 -r 0.25 -p 3 -m 5 --genepop\n",
    "```\n",
    "\n",
    "<br>Here:\n",
    "<br> -b 100 (batch num)\n",
    "<br> -P Stacks (directory w sstacks output files)\n",
    "<br> -M popmap_cragigrun1.txt (pop map)\n",
    "<br> -t 10 (threads)\n",
    "<br> -r .25 (percentage ind in pop required to process locus for pop)\n",
    "<br> -p 3 (min populations loci present in to keep locus)\n",
    "<br> -m 5 specify a minimum stack depth required for individuals at a locus.\n",
    "\n",
    "Output\n",
    "```\n",
    "Writing 28647 loci to summary statistics file, 'Stacks/batch_100.sumstats.tsv'\n",
    "Writing 28647 loci to observed haplotype file, 'Stacks/batch_100.haplotypes.tsv'\n",
    "Writing population data to GenePop file 'Stacks/batch_100.genepop'\n",
    "```\n",
    "\n",
    "Counted loci by columns in pop gen file - 1 (for first column of sample names):\n",
    "\n",
    "```\n",
    "nclowell@ubuntu:/mnt/hgfs/Data_for_Analysis/WorkingFolder$ python count_loci_genepop.py Stacks/batch_100.genepop\n",
    "Your genepop file has 232763 columns of genotypes.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bowtie + BLAST filtering\n",
    "\n",
    "6. Filtering loci with bowtie + BLAST\n",
    "\n",
    "We filter out highly repetive loci using bowtie and BLAST. More information in this markdown file. \n",
    "\n",
    "#### A. Filtering with bowtie\n",
    "Make a fasta file for bowtie by running a custom python script that Mary wrote, which requires (1) a text file with the header from the genepop file and (2) unzipped batch.catalog.tags file.\n",
    "\n",
    "Here, I will make batch_100_loci.txt for this round by manually opening the genepop file in Textwrangler, and cutting and pasting the header line with the tag names into its own text file.\n",
    "\n",
    "first bit of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_11,3_19,3_28,3_38,3_50,3_103,3_130,4_7,4_14,4_39,4_41,4_44,4_46,4_58,4_59,4_61,4_62,4_69,4_76,4_77,4_78,4_85,4_90,4_133,7_20,7_105,7_130,7_131,9_20,9_26,9_36,9_53,9_67,9_70,9_79,9_101,9_117,9_119,9_125,9_137,9_138,10_32,11_96,11_131,12_32,12_50,12_73,12_96,12_98,12_117,12_138,14_8,14_15,14_23,14_29,14_38,14_43,14_44,14_49,14_65,14_67,14_107,16_16,16_46,16_50,16_54,16_73,16_77,16_79,16_97,16_108,16_109,17_29,17_30,17_37,17_48,17_50,17_85,17_89,17_97,17_108,17_113,17_120,18_9,18_13,18_35,18_46,18_53,18_59,18_65,18_70,18_71,18_90,18_91,18_95,18_97,18_99,18_108,18_112,18_114,18_117,18_118,18_119,18_136,23_58,23_118,23_119,23_120,26_49,26_55,26_89,26_90,26_137,27_8,27_28,27_49,27_67,27_76,27_86,27_134,27_135,32_22,32_23,32_35,32_39,32_52,32_75,32_84,32_101,32_120,32_121,32_136,32_137,33_9,33_13,33_33,33_52,33_127,36_16,36_18,36_33,36_45,36_58,36_94,36_116,36_126,36_133,37_10,37_23,37_34,37_67,37_82,37_85,37_109,37_111,37_117,37_118,38_18,38_29,38_32,38_50,43_8,43_21,43_27,43_30,43_32,43_36,43_61,43_74,45_67,46_24,46_41,46_70,46_85,46_96,46_116,46_133,46_134,46_137,50_8,50_34,50_132,52_30,52_37,52_102,52_105,53_7,53_10,53_40,53_42,53_55,53_67,53_70,53_77,53_88,53_91,53_93,53_105,53_109,53_116,53_123,53_138,57_14,57_18,57_24,57_27,57_37,57_38,57_40,57_42,57_45,57_56,57_58,57_63,57_68,57_74,57_76,57_77,57_84,57_85,57_91,57_95,57_101,57_103,57_111,57_119,57_120,57_121,57_131,57_135,57_136,58_21,58_70,58_92,58_112,58_113,58_135,58_136,58_137,62_15,62_39,62_61,62_62,62_75,62_76,64_24,64_50,64_75,64_82,64_98,64_105,64_121,64_136,64_138,66_7,66_34,66_128,67_48,67_56,67_84,67_86,67_88,67_92,67_95,67_116,67_130,67_138,68_29,68_30,68_52,68_96,68_127,71_7,71_12,71_22,71_23,71_49,71_72,71_77,71_80,71_88,71_97,71_107,71_124,72_9,72_10,72_32,72_41,72_57,72_68,72_79,72_81,72_98,72_111,72_124,76_10,76_95,79_30,79_33,79_119,79_135,82_81,82_99,83_34,83_84,83_103,83_125,94_32,94_40,94_52,94_56,94_60,94_72,94_73,94_75,94_102,94_106,94_133,94_134,95_28,95_45,95_85,95_131,95_133,98_22,98_24,\r\n"
     ]
    }
   ],
   "source": [
    "!python get_first_line_genepop.py batch_100 batch_100_loci_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then I will unzip the catalog tags file with ``gzip -d batch_100.catalog.tags.tsv.gz``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Data_for_Analysis/WorkingFolder/Stacks\n"
     ]
    }
   ],
   "source": [
    "cd Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gzip -d batch_100.catalog.tags.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And now Mary's script..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!python gen_bowtie_fasta.py batch_100_loci_names.txt Stacks/batch_100.catalog.tags.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Installed bowtie by downloading the zipped folder, navigating to that folder, and running\n",
    "\n",
    "```\n",
    "nclowell@ubuntu:/mnt/hgfs/Data_for_Analysis/WorkingFolder/Bowtie/bowtie-1.2$ sudo apt install bowtie\n",
    "[sudo] password for nclowell: \n",
    "```\n",
    "\n",
    "Manually made a new folder to hold the bowtie software and files I make with bowtie.\n",
    "\n",
    "Now, make bowtie index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"batch_100.*.ebwt\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 5 (one in 32)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Max bucket size: default\n",
      "  Max bucket size, sqrt multiplier: default\n",
      "  Max bucket size, len divisor: 4\n",
      "  Difference-cover sample period: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  seqsforBOWTIE.fa\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 954860\n",
      "Using parameters --bmax 716145 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 716145 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 6; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 477429 (target: 716144)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:01\n",
      "  Sorting block of length 587728\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 587729\n",
      "Getting block 2 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 430345\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 430346\n",
      "Getting block 3 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 291143\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 291144\n",
      "Getting block 4 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 637647\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 637648\n",
      "Getting block 5 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 637536\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 637537\n",
      "Getting block 6 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 477289\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 477290\n",
      "Getting block 7 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 546629\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 546630\n",
      "Getting block 8 of 8\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 211118\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 211119\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 1123971\n",
      "fchr[G]: 1863730\n",
      "fchr[T]: 2618412\n",
      "fchr[$]: 3819442\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 5885248 bytes to primary EBWT file: batch_100.1.ebwt\n",
      "Wrote 477436 bytes to secondary EBWT file: batch_100.2.ebwt\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 3819442\n",
      "    bwtLen: 3819443\n",
      "    sz: 954861\n",
      "    bwtSz: 954861\n",
      "    lineRate: 6\n",
      "    linesPerSide: 1\n",
      "    offRate: 5\n",
      "    offMask: 0xffffffe0\n",
      "    isaRate: -1\n",
      "    isaMask: 0xffffffff\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 119358\n",
      "    offsSz: 477432\n",
      "    isaLen: 0\n",
      "    isaSz: 0\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 56\n",
      "    sideBwtLen: 224\n",
      "    numSidePairs: 8526\n",
      "    numSides: 17052\n",
      "    numLines: 17052\n",
      "    ebwtTotLen: 1091328\n",
      "    ebwtTotSz: 1091328\n",
      "    reverse: 0\n",
      "Total time for call to driver() for forward index: 00:00:04\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 954860\n",
      "Using parameters --bmax 716145 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 716145 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:01\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 2, merged 6; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 545634 (target: 716144)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 7\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 432195\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 432196\n",
      "Getting block 2 of 7\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 527983\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 527984\n",
      "Getting block 3 of 7\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 303252\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 303253\n",
      "Getting block 4 of 7\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 653457\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 653458\n",
      "Getting block 5 of 7\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 683581\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 683582\n",
      "Getting block 6 of 7\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 647813\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 647814\n",
      "Getting block 7 of 7\n",
      "  Reserving size (716145) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 571155\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 571156\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 1123971\n",
      "fchr[G]: 1863730\n",
      "fchr[T]: 2618412\n",
      "fchr[$]: 3819442\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 5885248 bytes to primary EBWT file: batch_100.rev.1.ebwt\n",
      "Wrote 477436 bytes to secondary EBWT file: batch_100.rev.2.ebwt\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 3819442\n",
      "    bwtLen: 3819443\n",
      "    sz: 954861\n",
      "    bwtSz: 954861\n",
      "    lineRate: 6\n",
      "    linesPerSide: 1\n",
      "    offRate: 5\n",
      "    offMask: 0xffffffe0\n",
      "    isaRate: -1\n",
      "    isaMask: 0xffffffff\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 119358\n",
      "    offsSz: 477432\n",
      "    isaLen: 0\n",
      "    isaSz: 0\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 56\n",
      "    sideBwtLen: 224\n",
      "    numSidePairs: 8526\n",
      "    numSides: 17052\n",
      "    numLines: 17052\n",
      "    ebwtTotLen: 1091328\n",
      "    ebwtTotSz: 1091328\n",
      "    reverse: 0\n",
      "Total time for backward call to driver() for mirror index: 00:00:05\n"
     ]
    }
   ],
   "source": [
    "!bowtie-build seqsforBOWTIE.fa batch_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now align sequenecs to the index you just made to identify any sequences that align to multiple places in the genome (maybe highly repetive loci like microsats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# reads processed: 27478\r\n",
      "# reads with at least one reported alignment: 27478 (100.00%)\r\n",
      "# reads that failed to align: 0 (0.00%)\r\n",
      "Reported 27478 alignments to 1 output stream(s)\r\n"
     ]
    }
   ],
   "source": [
    "!bowtie -f -v 3 --sam --sam-nohead \\\n",
    "batch_100 \\\n",
    "seqsforBOWTIE.fa \\\n",
    "batch_100_BOWTIEout.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then use Dan's custom script to remove unwanted sequences after bowtie alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bowtie output lines read: 27478 5089t lines read: 8637d: 14625 lines read: 17738owtie output lines read: 20232 lines read: 22858umber of Bowtie output lines read: 25545\n",
      "Number of sequences written to output: 27476ritten to output: 2655written to output: 646nces written to output: 789mber of sequences written to output: 956itten to output: 1166 output: 1352 of sequences written to output: 1562mber of sequences written to output: 1725sequences written to output: 1911s written to output: 2097 2306mber of sequences written to output: 2493sequences written to output: 2679s written to output: 2865n to output: 3051itten to output: 3214 output: 3400n to output: 3563mber of sequences written to output: 3773s written to output: 3889mber of sequences written to output: 40291 of sequences written to output: 4378n to output: 4587mber of sequences written to output: 4797mber of sequences written to output: 5053itten to output: 52621 output: 5704 of sequences written to output: 5914 of sequences written to output: 6170n to output: 6379mber of sequences written to output: 6589mber of sequences written to output: 6845itten to output: 7054 output: 7240 output: 7496 of sequences written to output: 7706 of sequences written to output: 7962 8194ences written to output: 8404mber of sequences written to output: 8637itten to output: 8846itten to output: 91021 output: 9544 9730n to output: 9963ritten to output: 10237ten to output: 10510n to output: 10692o output: 10965output: 11147itten to output: 11352mber of sequences written to output: 11580 to output: 11807s written to output: 12012ritten to output: 12285umber of sequences written to output: 12513nces written to output: 12763o output: 130133umber of sequences written to output: 13537nces written to output: 137874014 sequences written to output: 14265tten to output: 14515ber of sequences written to output: 14743 of sequences written to output: 15016written to output: 15266ber of sequences written to output: 15767es written to output: 16017written to output: 16290put: 16540ences written to output: 16768to output: 1701868equences written to output: 17519en to output: 1776918019f sequences written to output: 18270itten to output: 18520mber of sequences written to output: 18748 to output: 18975 output: 19248 sequences written to output: 19385tten to output: 19635ber of sequences written to output: 19863r of sequences written to output: 20045of sequences written to output: 202271tten to output: 20659ences written to output: 20864to output: 21114 written to output: 21319sequences written to output: 21524quences written to output: 21706ber of sequences written to output: 2191122115 output: 22320tput: 22593t: 22866r of sequences written to output: 23117 written to output: 23367uences written to output: 23845er of sequences written to output: 24050 of sequences written to output: 2423236ten to output: 24846n to output: 25028to output: 252103691put: 25756t: 25938 to output: 26143o output: 26325written to output: 26530tput: 26689ut: 26871ber of sequences written to output: 2703127235417\n"
     ]
    }
   ],
   "source": [
    "!python parseBowtie_DD.py batch_100_BOWTIEout.sam batch_100_BOWTIEout_filtered.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I ran this command in the terminal outside jupyter notebook because the auto updating of the sys.stout.write() was freakin' out the notebook.\n",
    "\n",
    "```\n",
    "python parseBowtie_DD.py batch_100_BOWTIEout.sam batch_100_BOWTIEout_filtered.fa\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Number of Bowtie output lines read: 27478\n",
    "Number of sequences written to output: 27476\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To see how many loci were filtered out due to Bowtie, first count how many unique loci were in the genepop file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your genepop file has 232763 columns of genotypes.\r\n"
     ]
    }
   ],
   "source": [
    "!python count_loci_genepop.py Stacks/batch_100.genepop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I think that means Bowtie filtered out a ton of loci. 232763-27478 = 205285 = 88%\n",
    "\n",
    "That's sort of insane compared to when I ran through the Pacific cod data, but I did use extremely lenient parameters on this run of populations.\n",
    "\n",
    "## Filtering with Blast\n",
    "\n",
    "Make a blast database with filtered output from Bowtie filtering, then blast sequences to database and remove any loci that match other loci equally well or better than to themselves. This is supposed to remove highly repetitive loci like microsatellites that can interfere with our data analysis.\n",
    "\n",
    "Need to install Blast, make sure I can run it from anywhere, make a directory for Blast files, move the filtered bowtie fasta there, then blast sequences to the database and filter with Dan's Blast parsing script.\n",
    "\n",
    "First step... install Blast on Ubuntu:\n",
    "\n",
    "```\n",
    "nclowell@ubuntu:/mnt/hgfs/Data_for_Analysis/WorkingFolder$ sudo apt-get install ncbi-blast+\n",
    "```\n",
    "\n",
    "Make sure blast is working:\n",
    "```\n",
    "nclowell@ubuntu:/mnt/hgfs/Data_for_Analysis/WorkingFolder$ blastp\n",
    "BLAST query/options error: Either a BLAST database or subject sequence(s) must be specified\n",
    "Please refer to the BLAST+ user manual.\n",
    "```\n",
    "Now, make a directory for Blast files.\n",
    "\n",
    "<img src=\"bowtie_folder_made.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 02/09/2017 11:04:48\n",
      "New DB name:   /mnt/hgfs/Data_for_Analysis/WorkingFolder/Blast/batch_100_BOWTIEfiltered\n",
      "New DB title:  batch_100_BOWTIEout_filtered.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep Linkouts: T\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 27476 sequences in 0.571891 seconds.\n"
     ]
    }
   ],
   "source": [
    "!makeblastdb -in batch_100_BOWTIEout_filtered.fa \\\n",
    "-parse_seqids \\\n",
    "-dbtype nucl \\\n",
    "-out batch_100_BOWTIEfiltered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now blast against itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!blastn -query batch_100_BOWTIEout_filtered.fa \\\n",
    "-db batch_100_BOWTIEfiltered \\\n",
    "-out batch_100_BowtieBlastFiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use Dan's python script to filter only wanted loci:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It was crashing the notebook... in the terminal I ran:\n",
    "```\n",
    "nclowell@ubuntu:/mnt/hgfs/Data_for_Analysis/WorkingFolder/Blast$ python checkBlastResults_DD.py \\\n",
    "> batch_100_BowtieBlastFiltered \\\n",
    "> batch_100_BOWTIEout_filtered.fa \\\n",
    "> batch_100_BowtieBlastFiltered_GOOD.fa \\\n",
    "> batch_100_BowtieBlastFiltered_BAD.fa\n",
    "\n",
    "Identifying which loci are 'good' and 'bad' based on BLAST alignments...\n",
    "Writing 'good' and 'bad' loci to their respective files...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, check how many loci were filtered out during the BLAST phase of filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Data_for_Analysis/WorkingFolder/Blast\n"
     ]
    }
   ],
   "source": [
    "cd Data_for_Analysis/WorkingFolder/Blast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27460\r\n"
     ]
    }
   ],
   "source": [
    "!grep \">\" batch_100_BowtieBlastFiltered_GOOD.fa | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\r\n"
     ]
    }
   ],
   "source": [
    "!grep \">\" batch_100_BowtieBlastFiltered_BAD.fa | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So that makes 27460 - 16 = 27444, or <.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creating final reference genome with Bowtie\n",
    "\n",
    "Lastly, I need to use Bowtie again to build a final Bowtie index using the files cleaned in Blast, and then use Bowtie to align all of my fastq files to the Bowtie index for pstacks. So I manually need to move the output files from Blast to the Bowtie folder. Its these alignments (of each fastq with the final reference genome) that feed into ``pstacks``.\n",
    "\n",
    "Ran this outside the notebook because it crashes the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!bowtie-build batch_100_BowtieBlastFiltered_GOOD.fa batch_100_final_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, need to align each fastq file against final reference genome. I made a Python script to write that bash script. Going to see if it needs updating...\n",
    "\n",
    "Sample bash script line:\n",
    "``bowtie -q -v 3 --norc --sam Blast/batch_100_final_index Stacks/Q351.fq Q351.sam``\n",
    "\n",
    "Output:\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "Now into ``pstacks``!\n",
    "\n",
    "## ``pstacks``\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
