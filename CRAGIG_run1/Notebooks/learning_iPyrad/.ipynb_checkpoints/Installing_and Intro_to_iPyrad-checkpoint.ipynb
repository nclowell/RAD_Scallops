{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and Intro to iPyrad\n",
    "\n",
    "**20170512**\n",
    "Here, I'm documenting installation and version number, going through the walkthrough provided on the iPyrad website, and taking notes from looking through documentation.\n",
    "\n",
    "\n",
    "## Installing iPyrad\n",
    "\n",
    "**20170511**\n",
    "\n",
    "I just installed iPyrad v 0.6.20 using this [installation tutorial](http://ipyrad.readthedocs.io/installation.html). I first installed MiniConda2 and used that to install iPyrad:\n",
    "\n",
    "```\n",
    "wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh\n",
    "bash Miniconda2-latest-Linux-x86_64.sh\n",
    "```\n",
    "and then:\n",
    "\n",
    "```\n",
    "conda install -c ipyrad ipyrad\n",
    "```\n",
    "\n",
    "If I want to update my version of iPyrad, I can use:\n",
    "\n",
    "```\n",
    "conda update -c ipyrad ipyrad \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyrad 0.6.20\r\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipyrad [-h] [-v] [-r] [-f] [-q] [-d] [-n new] [-p params]\r\n",
      "              [-b [branch [branch ...]]] [-m [merge [merge ...]]] [-s steps]\r\n",
      "              [-c cores] [-t threading] [--MPI] [--preview] [--ipcluster]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -v, --version         show program's version number and exit\r\n",
      "  -r, --results         show results summary for Assembly in params.txt and\r\n",
      "                        exit\r\n",
      "  -f, --force           force overwrite of existing data\r\n",
      "  -q, --quiet           do not print to stderror or stdout.\r\n",
      "  -d, --debug           print lots more info to ipyrad_log.txt.\r\n",
      "  -n new                create new file 'params-{new}.txt' in current\r\n",
      "                        directory\r\n",
      "  -p params             path to params file for Assembly:\r\n",
      "                        params-{assembly_name}.txt\r\n",
      "  -b [branch [branch ...]]\r\n",
      "                        create a new branch of the Assembly as\r\n",
      "                        params-{branch}.txt\r\n",
      "  -m [merge [merge ...]]\r\n",
      "                        merge all assemblies provided into a new assembly\r\n",
      "  -s steps              Set of assembly steps to perform, e.g., -s 123\r\n",
      "                        (Default=None)\r\n",
      "  -c cores              number of CPU cores to use (Default=0=All)\r\n",
      "  -t threading          tune threading of binaries (Default=2)\r\n",
      "  --MPI                 connect to parallel CPUs across multiple nodes\r\n",
      "  --preview             run ipyrad in preview mode. Subset the input file so\r\n",
      "                        it'll runquickly so you can verify everything is\r\n",
      "                        working\r\n",
      "  --ipcluster           connect to running ipcluster instance with default\r\n",
      "                        cluster-id=''\r\n",
      "\r\n",
      "  * Example command-line usage: \r\n",
      "    ipyrad -n data                       ## create new file called params-data.txt \r\n",
      "    ipyrad -p params-data.txt            ## run ipyrad with settings in params file\r\n",
      "    ipyrad -p params-data.txt -s 123     ## run only steps 1-3 of assembly.\r\n",
      "    ipyrad -p params-data.txt -s 3 -f    ## run step 3, overwrite existing data.\r\n",
      "\r\n",
      "  * HPC parallelization across 32 cores\r\n",
      "    ipyrad -p params-data.txt -s 3 -c 32 --MPI\r\n",
      "\r\n",
      "  * Print results summary \r\n",
      "    ipyrad -p params-data.txt -r \r\n",
      "\r\n",
      "  * Branch/Merging Assemblies\r\n",
      "    ipyrad -p params-data.txt -b newdata  \r\n",
      "    ipyrad -m newdata params-1.txt params-2.txt [params-3.txt, ...]\r\n",
      "\r\n",
      "  * Subsample taxa during branching\r\n",
      "    ipyrad -p params-data.txt -b newdata taxaKeepList.txt\r\n",
      "\r\n",
      "  * Documentation: http://ipyrad.readthedocs.io\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!ipyrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory Tutorial\n",
    "\n",
    "The folks who made iPyrad provide an introductory tutorial [here](http://ipyrad.readthedocs.io/tutorial_intro_cli.html). I'm going to use it to get the hang of the program.\n",
    "\n",
    "#### Get the tutorial data\n",
    "Navigate to the directory where you want to store the data. It will create a new folder with the data there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   147  100   147    0     0    471      0 --:--:-- --:--:-- --:--:--   471\n",
      "100 11.8M  100 11.8M    0     0  8433k      0  0:00:01  0:00:01 --:--:-- 46.6M\n"
     ]
    }
   ],
   "source": [
    "!curl -LkO https://github.com/dereneaton/ipyrad/raw/master/tests/ipsimdata.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ipsimdata/\n",
      "./ipsimdata/pairgbs_example_R2_.fastq.gz\n",
      "./ipsimdata/pairgbs_wmerge_example_barcodes.txt\n",
      "./ipsimdata/rad_example_genome.fa\n",
      "./ipsimdata/pairddrad_example_genome.fa\n",
      "./ipsimdata/pairgbs_example_R1_.fastq.gz\n",
      "./ipsimdata/pairgbs_wmerge_example_R2_.fastq.gz\n",
      "./ipsimdata/rad_example_genome.fa.fai\n",
      "./ipsimdata/pairddrad_example_R2_.fastq.gz\n",
      "./ipsimdata/pairddrad_example_genome.fa.sma\n",
      "./ipsimdata/pairddrad_example_genome.fa.fai\n",
      "./ipsimdata/pairgbs_wmerge_example_genome.fa\n",
      "./ipsimdata/pairddrad_wmerge_example_genome.fa\n",
      "./ipsimdata/pairddrad_example_genome.fa.smi\n",
      "./ipsimdata/pairgbs_wmerge_example_R1_.fastq.gz\n",
      "./ipsimdata/rad_example_genome.fa.smi\n",
      "./ipsimdata/gbs_example_barcodes.txt\n",
      "./ipsimdata/pairgbs_example_barcodes.txt\n",
      "./ipsimdata/pairddrad_example_R1_.fastq.gz\n",
      "./ipsimdata/pairddrad_wmerge_example_barcodes.txt\n",
      "./ipsimdata/rad_example_barcodes.txt\n",
      "./ipsimdata/pairddrad_wmerge_example_R1_.fastq.gz\n",
      "./ipsimdata/pairddrad_wmerge_example_R2_.fastq.gz\n",
      "./ipsimdata/gbs_example_R1_.fastq.gz\n",
      "./ipsimdata/pairddrad_example_barcodes.txt\n",
      "./ipsimdata/rad_example_genome.fa.sma\n",
      "./ipsimdata/rad_example_R1_.fastq.gz\n",
      "./ipsimdata/gbs_example_genome.fa\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf ipsimdata.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mgbs_example_barcodes.txt\u001b[0m*               \u001b[01;32mpairgbs_example_barcodes.txt\u001b[0m*\r\n",
      "\u001b[01;32mgbs_example_genome.fa\u001b[0m*                  \u001b[01;32mpairgbs_example_R1_.fastq.gz\u001b[0m*\r\n",
      "\u001b[01;32mgbs_example_R1_.fastq.gz\u001b[0m*               \u001b[01;32mpairgbs_example_R2_.fastq.gz\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_example_barcodes.txt\u001b[0m*         \u001b[01;32mpairgbs_wmerge_example_barcodes.txt\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_example_genome.fa\u001b[0m*            \u001b[01;32mpairgbs_wmerge_example_genome.fa\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_example_genome.fa.fai\u001b[0m*        \u001b[01;32mpairgbs_wmerge_example_R1_.fastq.gz\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_example_genome.fa.sma\u001b[0m*        \u001b[01;32mpairgbs_wmerge_example_R2_.fastq.gz\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_example_genome.fa.smi\u001b[0m*        \u001b[01;32mrad_example_barcodes.txt\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_example_R1_.fastq.gz\u001b[0m*         \u001b[01;32mrad_example_genome.fa\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_example_R2_.fastq.gz\u001b[0m*         \u001b[01;32mrad_example_genome.fa.fai\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_wmerge_example_barcodes.txt\u001b[0m*  \u001b[01;32mrad_example_genome.fa.sma\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_wmerge_example_genome.fa\u001b[0m*     \u001b[01;32mrad_example_genome.fa.smi\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_wmerge_example_R1_.fastq.gz\u001b[0m*  \u001b[01;32mrad_example_R1_.fastq.gz\u001b[0m*\r\n",
      "\u001b[01;32mpairddrad_wmerge_example_R2_.fastq.gz\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls ipsimdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@lane1_locus0_2G_0_0 1:N:0:\r\n",
      "CTCCAATCCTGCAGTTTAACTGTTCAAGTTGGCAAGATCAAGTCGTCCCTAGCCCCCGCGTCCGTTTTTACCTGGTCGCGGTCCCGACCCAGCTGCCCCC\r\n",
      "+\r\n",
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\r\n",
      "@lane1_locus0_2G_0_1 1:N:0:\r\n",
      "CTCCAATCCTGCAGTTTAACTGTTCAAGTTGGCAAGATCAAGTCGTCCCTAGCCCCCGCGTCCGTTTTTACCTGGTCGCGGTCCCCACCCAGCTGCCCCC\r\n",
      "+\r\n",
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\r\n",
      "@lane1_locus0_2G_0_2 1:N:0:\r\n",
      "CTCCAATCCTGCAGTTTAACTGTTCAAGTTGGCAAGATCAAGTCGTCCCTAGCCCCCGCGTCCGTTTTTACCTGGTCGCGGTCCCGACCCAGCTGCCCCC\r\n",
      "+\r\n",
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# look at first three reads\n",
    "!gunzip -c ./ipsimdata/rad_example_R1_.fastq.gz | head -n 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A_0\tCATCATCAT\r\n",
      "1B_0\tCCAGTGATA\r\n",
      "1C_0\tTGGCCTAGT\r\n",
      "1D_0\tGGGAAAAAC\r\n",
      "2E_0\tGTGGATATC\r\n",
      "2F_0\tAGAGCCGAG\r\n",
      "2G_0\tCTCCAATCC\r\n",
      "2H_0\tCTCACTGCA\r\n",
      "3I_0\tGGCGCATAC\r\n",
      "3J_0\tCCTTATGTC\r\n",
      "3K_0\tACGTGTGTG\r\n",
      "3L_0\tTTACTAACA\r\n"
     ]
    }
   ],
   "source": [
    "# look at barcodes file\n",
    "!cat ./ipsimdata/rad_example_barcodes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make params file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  New file 'params-iptest.txt' created in /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -n iptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ipyrad params file (v.0.6.20)-------------------------------------------\r\n",
      "iptest                         ## [0] [assembly_name]: Assembly name. Used to name output directories for assembly steps\r\n",
      "./                             ## [1] [project_dir]: Project dir (made in curdir if not present)\r\n",
      "                               ## [2] [raw_fastq_path]: Location of raw non-demultiplexed fastq files\r\n",
      "                               ## [3] [barcodes_path]: Location of barcodes file\r\n",
      "                               ## [4] [sorted_fastq_path]: Location of demultiplexed/sorted fastq files\r\n",
      "denovo                         ## [5] [assembly_method]: Assembly method (denovo, reference, denovo+reference, denovo-reference)\r\n",
      "                               ## [6] [reference_sequence]: Location of reference sequence file\r\n",
      "rad                            ## [7] [datatype]: Datatype (see docs): rad, gbs, ddrad, etc.\r\n",
      "TGCAG,                         ## [8] [restriction_overhang]: Restriction overhang (cut1,) or (cut1, cut2)\r\n",
      "5                              ## [9] [max_low_qual_bases]: Max low quality base calls (Q<20) in a read\r\n",
      "33                             ## [10] [phred_Qscore_offset]: phred Q score offset (33 is default and very standard)\r\n",
      "6                              ## [11] [mindepth_statistical]: Min depth for statistical base calling\r\n",
      "6                              ## [12] [mindepth_majrule]: Min depth for majority-rule base calling\r\n",
      "10000                          ## [13] [maxdepth]: Max cluster depth within samples\r\n",
      "0.85                           ## [14] [clust_threshold]: Clustering threshold for de novo assembly\r\n",
      "0                              ## [15] [max_barcode_mismatch]: Max number of allowable mismatches in barcodes\r\n",
      "0                              ## [16] [filter_adapters]: Filter for adapters/primers (1 or 2=stricter)\r\n",
      "35                             ## [17] [filter_min_trim_len]: Min length of reads after adapter trim\r\n",
      "2                              ## [18] [max_alleles_consens]: Max alleles per site in consensus sequences\r\n",
      "5, 5                           ## [19] [max_Ns_consens]: Max N's (uncalled bases) in consensus (R1, R2)\r\n",
      "8, 8                           ## [20] [max_Hs_consens]: Max Hs (heterozygotes) in consensus (R1, R2)\r\n",
      "4                              ## [21] [min_samples_locus]: Min # samples per locus for output\r\n",
      "20, 20                         ## [22] [max_SNPs_locus]: Max # SNPs per locus (R1, R2)\r\n",
      "8, 8                           ## [23] [max_Indels_locus]: Max # of indels per locus (R1, R2)\r\n",
      "0.5                            ## [24] [max_shared_Hs_locus]: Max # heterozygous sites per locus (R1, R2)\r\n",
      "0, 0, 0, 0                     ## [25] [trim_reads]: Trim raw read edges (R1>, <R1, R2>, <R2) (see docs)\r\n",
      "0, 0, 0, 0                     ## [26] [trim_loci]: Trim locus edges (see docs) (R1>, <R1, R2>, <R2)\r\n",
      "p, s, v                        ## [27] [output_formats]: Output formats (see docs)\r\n",
      "                               ## [28] [pop_assign_file]: Path to population assignment file"
     ]
    }
   ],
   "source": [
    ">>> cat params-iptest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the params file to include the path to the raw files and the path to the barcodes file. I did this in Atom:\n",
    "\n",
    "![imge](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_run1/Notebooks/images_for_notebooks/change_params.png?raw=true)\n",
    "\n",
    "#### Step 1: Demultiplex\n",
    "\n",
    "There are 4 main parts to this step: (1) It creates a new Assembly called iptest, since this is our first time running any steps for the named assembly; (2) It launches a number of parallel Engines, by default this is the number of available CPUs on your machine; (3) It performs the step functions, in this case it sorts the data and writes the outputs; and (4) It saves the Assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  loading Assembly: iptest\n",
      "  from saved path: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest.json\n",
      "  host compute node: [1 cores] on ubuntu\n",
      "\n",
      "  Step 1: Demultiplexing fastq data to Samples\n",
      "    Skipping: 12 Samples already found in Assembly iptest.\n",
      "    (can overwrite with force argument)    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-iptest.txt -s 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A_0_R1_.fastq.gz  2F_0_R1_.fastq.gz  3K_0_R1_.fastq.gz\r\n",
      "1B_0_R1_.fastq.gz  2G_0_R1_.fastq.gz  3L_0_R1_.fastq.gz\r\n",
      "1C_0_R1_.fastq.gz  2H_0_R1_.fastq.gz  s1_demultiplex_stats.txt\r\n",
      "1D_0_R1_.fastq.gz  3I_0_R1_.fastq.gz\r\n",
      "2E_0_R1_.fastq.gz  3J_0_R1_.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "# look at results of this step in fastqs output directory\n",
    "!ls iptest_fastqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary stats of Assembly iptest\n",
      "------------------------------------------------\n",
      "      state  reads_raw\n",
      "1A_0      1      19862\n",
      "1B_0      1      20043\n",
      "1C_0      1      20136\n",
      "1D_0      1      19966\n",
      "2E_0      1      20017\n",
      "2F_0      1      19933\n",
      "2G_0      1      20030\n",
      "2H_0      1      20199\n",
      "3I_0      1      19885\n",
      "3J_0      1      19822\n",
      "3K_0      1      19965\n",
      "3L_0      1      20008\n",
      "\n",
      "\n",
      "Full stats files\n",
      "------------------------------------------------\n",
      "step 1: ./iptest_fastqs/s1_demultiplex_stats.txt\n",
      "step 2: None\n",
      "step 3: None\n",
      "step 4: None\n",
      "step 5: None\n",
      "step 6: None\n",
      "step 7: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -r fetches informative results from currently executed steps like raw reads with -r\n",
    "!ipyrad -p params-iptest.txt -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_file                               total_reads    cut_found  bar_matched\r\n",
      "rad_example_R1_.fastq                       239866       239866       239866\r\n",
      "\r\n",
      "sample_name                            total_reads\r\n",
      "1A_0                                         19862\r\n",
      "1B_0                                         20043\r\n",
      "1C_0                                         20136\r\n",
      "1D_0                                         19966\r\n",
      "2E_0                                         20017\r\n",
      "2F_0                                         19933\r\n",
      "2G_0                                         20030\r\n",
      "2H_0                                         20199\r\n",
      "3I_0                                         19885\r\n",
      "3J_0                                         19822\r\n",
      "3K_0                                         19965\r\n",
      "3L_0                                         20008\r\n",
      "\r\n",
      "sample_name                               true_bar       obs_bar     N_records\r\n",
      "1A_0                                     CATCATCAT     CATCATCAT         19862\r\n",
      "1B_0                                     CCAGTGATA     CCAGTGATA         20043\r\n",
      "1C_0                                     TGGCCTAGT     TGGCCTAGT         20136\r\n",
      "1D_0                                     GGGAAAAAC     GGGAAAAAC         19966\r\n",
      "2E_0                                     GTGGATATC     GTGGATATC         20017\r\n",
      "2F_0                                     AGAGCCGAG     AGAGCCGAG         19933\r\n",
      "2G_0                                     CTCCAATCC     CTCCAATCC         20030\r\n",
      "2H_0                                     CTCACTGCA     CTCACTGCA         20199\r\n",
      "3I_0                                     GGCGCATAC     GGCGCATAC         19885\r\n",
      "3J_0                                     CCTTATGTC     CCTTATGTC         19822\r\n",
      "3K_0                                     ACGTGTGTG     ACGTGTGTG         19965\r\n",
      "3L_0                                     TTACTAACA     TTACTAACA         20008\r\n",
      "no_match                                         _            _            0\r\n"
     ]
    }
   ],
   "source": [
    "# to see full stats from step one, try\n",
    "!cat ./iptest_fastqs/s1_demultiplex_stats.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Filter reads\n",
    "\n",
    "This step filters reads based on quality scores, and can be used to detect Illumina adapters in your reads, which is a common concern with any NGS data set, and especially so for homebrew type library preparations. Here the filter is set to the default value of 0 (zero), meaning it filters only based on quality scores of base calls, and does not search for adapters. This is a good option if your data are already pre-filtered. The resuling filtered files from step 2 are written to a new directory called ``iptest_edits/``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  loading Assembly: iptest\n",
      "  from saved path: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest.json\n",
      "  host compute node: [1 cores] on ubuntu\n",
      "\n",
      "  Step 2: Filtering reads \n",
      "  [####################] 100%  processing reads      | 0:00:08  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter only based on quality scores (will not search for adapters)\n",
    "!ipyrad -p params-iptest.txt -s 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A_0.trimmed_R1_.fastq.gz  2F_0.trimmed_R1_.fastq.gz  3K_0.trimmed_R1_.fastq.gz\r\n",
      "1B_0.trimmed_R1_.fastq.gz  2G_0.trimmed_R1_.fastq.gz  3L_0.trimmed_R1_.fastq.gz\r\n",
      "1C_0.trimmed_R1_.fastq.gz  2H_0.trimmed_R1_.fastq.gz  s2_rawedit_stats.txt\r\n",
      "1D_0.trimmed_R1_.fastq.gz  3I_0.trimmed_R1_.fastq.gz\r\n",
      "2E_0.trimmed_R1_.fastq.gz  3J_0.trimmed_R1_.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "# view the output of filtering\n",
    "!ls iptest_edits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary stats of Assembly iptest\n",
      "------------------------------------------------\n",
      "      state  reads_raw  reads_passed_filter\n",
      "1A_0      2      19862                19862\n",
      "1B_0      2      20043                20043\n",
      "1C_0      2      20136                20136\n",
      "1D_0      2      19966                19966\n",
      "2E_0      2      20017                20017\n",
      "2F_0      2      19933                19933\n",
      "2G_0      2      20030                20030\n",
      "2H_0      2      20199                20199\n",
      "3I_0      2      19885                19885\n",
      "3J_0      2      19822                19822\n",
      "3K_0      2      19965                19965\n",
      "3L_0      2      20008                20008\n",
      "\n",
      "\n",
      "Full stats files\n",
      "------------------------------------------------\n",
      "step 1: ./iptest_fastqs/s1_demultiplex_stats.txt\n",
      "step 2: ./iptest_edits/s2_rawedit_stats.txt\n",
      "step 3: None\n",
      "step 4: None\n",
      "step 5: None\n",
      "step 6: None\n",
      "step 7: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get current stats including # raw reads and # reads after filtering.\n",
    "!ipyrad -p params-iptest.txt -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial provides a line to look at filtered reads, but couldn't get line of code to work. Might be because there's also a discrepancy in the name of the filtered files (on my computer, they say \"trimmed\" and in the tutorial they don't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open './iptest_edits/1A_0_R1_.fastq' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 12 ./iptest_edits/1A_0_R1_.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clustering within samples\n",
    "Step 3 de-replicates and then clusters reads within each sample by the set clustering threshold and then writes the clusters to new files in a directory called ``iptest_clust_0.85/``. Intuitively we are trying to identify all the reads that map to the same locus within each sample. The clustering threshold specifies the minimum percentage of sequence similarity below which we will consider two reads to have come from different loci.\n",
    "\n",
    "The true name of this output directory will be dictated by the value you set for the clust_threshold parameter in the params file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  loading Assembly: iptest\n",
      "  from saved path: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest.json\n",
      "  host compute node: [1 cores] on ubuntu\n",
      "\n",
      "  Step 3: Clustering/Mapping reads\n",
      "  [####################] 100%  dereplicating         | 0:00:01  \n",
      "  [####################] 100%  clustering            | 0:00:03  \n",
      "  [####################] 100%  building clusters     | 0:00:00  \n",
      "  [####################] 100%  chunking              | 0:00:00  \n",
      "  [####################] 100%  aligning              | 0:00:26  \n",
      "  [####################] 100%  concatenating         | 0:00:00  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cluster based on % similarity in params file, here default = .85\n",
    "!ipyrad -p params-iptest.txt -s 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary stats of Assembly iptest\n",
      "------------------------------------------------\n",
      "      state  reads_raw  reads_passed_filter  clusters_total  clusters_hidepth\n",
      "1A_0      3      19862                19862            1000              1000\n",
      "1B_0      3      20043                20043            1000              1000\n",
      "1C_0      3      20136                20136            1000              1000\n",
      "1D_0      3      19966                19966            1000              1000\n",
      "2E_0      3      20017                20017            1000              1000\n",
      "2F_0      3      19933                19933            1000              1000\n",
      "2G_0      3      20030                20030            1000              1000\n",
      "2H_0      3      20199                20199            1000              1000\n",
      "3I_0      3      19885                19885            1000              1000\n",
      "3J_0      3      19822                19822            1000              1000\n",
      "3K_0      3      19965                19965            1000              1000\n",
      "3L_0      3      20008                20008            1000              1000\n",
      "\n",
      "\n",
      "Full stats files\n",
      "------------------------------------------------\n",
      "step 1: ./iptest_fastqs/s1_demultiplex_stats.txt\n",
      "step 2: ./iptest_edits/s2_rawedit_stats.txt\n",
      "step 3: ./iptest_clust_0.85/s3_cluster_stats.txt\n",
      "step 4: None\n",
      "step 5: None\n",
      "step 6: None\n",
      "step 7: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check out the stats output\n",
    "!ipyrad -p params-iptest.txt -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aligned clusters found during this step are now located in ./iptest_clust_0.85/. You can get a feel for what this looks like by examining a portion of one of the files using the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane1_locus100_1A_0_0;size=18;*\r\n",
      "TGCAGCAAGATCACGGCGGACAGAACCGCCCCTTTTCTTGTTGCTGGTTAACTTCACGCCGTCATGGTTAGTGGTCAGGCTTTACAGGTCC\r\n",
      "lane1_locus100_1A_0_14;size=1;+\r\n",
      "TGCAGCAAGATCACGGCGGACAGAACCGCCCCTTTGCTTGTTGCTGGTTAACTTCTCGCCGTCATGGTTAGTGGTCAGGCTTTACAGGTCC\r\n",
      "lane1_locus100_1A_0_2;size=1;+\r\n",
      "TGCAGCAAGATCACGGCGGACAGAACCGCCCCTTTTCTTGTTGCTGGTTAACTTCACGCCGTCATGGTTAGTGGACAGGCTTTACAGGTCC\r\n",
      "//\r\n",
      "//\r\n",
      "lane1_locus10_1A_0_1;size=17;*\r\n",
      "TGCAGACGTGATGGCTATCCATAGAGCGCCTTATTTGCGGGTACGTACACCCATCATGTGCCCCGAAGACTGGGTGATTTCGCCCGAGCGT\r\n",
      "lane1_locus10_1A_0_0;size=1;+\r\n",
      "TGCAGACGTGATGGCTATCCATAGAGCGCCTTATTTGCTGGTACGTACACCCATCATGTGCCCCGAAGACTGGGTGATTTCGCCCGAGCGT\r\n",
      "lane1_locus10_1A_0_2;size=1;+\r\n",
      "TGCAGACGTGATGGCTATCCATAGAGCGCCTTATTTGCGGGTACGTACACCCATCATGTGCCCCGAAGACTGGGTCATTTCGCCCGAGCGT\r\n",
      "lane1_locus10_1A_0_8;size=1;+\r\n",
      "TGCAGACGTGATGGCTATCCATAGAGCGCCTTATTTGCGGGTACGTGCACCCATCATGTGCCCCGAAGACTGGGTGATTTCGCCCGAGCGT\r\n",
      "//\r\n",
      "//\r\n",
      "lane1_locus102_1A_0_0;size=16;*\r\n",
      "TGCAGGAGCGGTGCTACGTCGTGATGCCTTCACCCTCAATGTTAATAGCAGGTCAGGGCCTAATTTGATAATGACTAACCTGTAAACCTAC\r\n",
      "lane1_locus102_1A_0_7;size=1;+\r\n",
      "TGCAGGAGCGGTGCTACGTCGTGATGCCTTCACCCTCAATGTTAATAGCAGGTCAGGGCCTAATCTGATAATGACTAACCTGTAAACCTAC\r\n",
      "//\r\n",
      "//\r\n",
      "lane1_locus103_1A_0_0;size=16;*\r\n",
      "TGCAGCACGAAGTTAACTTCAACCCTCGCCACTACTGCGTACAAAACGCGAGAGGTCTCCATGAGTGTCGCATCCGCTGTGGTGGTTACAT\r\n",
      "lane1_locus103_1A_0_8;size=1;+\r\n",
      "TGCAGAACGAAGTTAACTTCAACCCTCGCCACTACTGCGTACAAAACGCGAGAGGTCTCCATGAGTGTCGCATCCGCTGTGGTGGTTACAT\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "## Same as above, gunzip -c means print to the screen and\n",
    "## `head -n 28` means just show me the first 28 lines. If\n",
    "## you're interested in what more of the loci look like\n",
    "## you can increase the number of lines you ask head for,\n",
    "## e.g. ... | head -n 100\n",
    "!gunzip -c iptest_clust_0.85/1A_0.clustS.gz | head -n 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``size =`` refers to the number of reads of that sequence. So between each ``// //`` is all the different sequences that were clustered together, and the number of times they appeared.\n",
    "\n",
    "### Step 4: Join estimation of heterozygosity and error rate\n",
    "\n",
    "Step 4 jointly estimates sequencing error rate and heterozygosity to disentangle which reads are “real” and which are sequencing error. We need to know which reads are “real” because in diploid organisms there are a maximum of 2 alleles at any given locus. If we look at the raw data and there are 5 or ten different “alleles”, and 2 of them are very high frequency, and the rest are singletons then this gives us evidence that the 2 high frequency alleles are good reads and the rest are probably not. This step is pretty straightforward, and pretty fast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  loading Assembly: iptest\n",
      "  from saved path: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest.json\n",
      "  host compute node: [1 cores] on ubuntu\n",
      "\n",
      "  Step 4: Joint estimation of error rate and heterozygosity\n",
      "  [####################] 100%  inferring [H, E]      | 0:00:09  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-iptest.txt -s 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step does not produce new output files, only a stats file with the estimated heterozygosity and error rate parameters. You can also invoke the ``-r`` flag to see the estimated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary stats of Assembly iptest\n",
      "------------------------------------------------\n",
      "      state  reads_raw  reads_passed_filter  clusters_total  clusters_hidepth  \\\n",
      "1A_0      4      19862                19862            1000              1000   \n",
      "1B_0      4      20043                20043            1000              1000   \n",
      "1C_0      4      20136                20136            1000              1000   \n",
      "1D_0      4      19966                19966            1000              1000   \n",
      "2E_0      4      20017                20017            1000              1000   \n",
      "2F_0      4      19933                19933            1000              1000   \n",
      "2G_0      4      20030                20030            1000              1000   \n",
      "2H_0      4      20199                20199            1000              1000   \n",
      "3I_0      4      19885                19885            1000              1000   \n",
      "3J_0      4      19822                19822            1000              1000   \n",
      "3K_0      4      19965                19965            1000              1000   \n",
      "3L_0      4      20008                20008            1000              1000   \n",
      "\n",
      "      hetero_est  error_est  \n",
      "1A_0    0.001824   0.000759  \n",
      "1B_0    0.001908   0.000752  \n",
      "1C_0    0.002084   0.000745  \n",
      "1D_0    0.001803   0.000761  \n",
      "2E_0    0.001830   0.000766  \n",
      "2F_0    0.001996   0.000755  \n",
      "2G_0    0.001940   0.000763  \n",
      "2H_0    0.001747   0.000756  \n",
      "3I_0    0.001807   0.000758  \n",
      "3J_0    0.001931   0.000776  \n",
      "3K_0    0.002092   0.000766  \n",
      "3L_0    0.002042   0.000748  \n",
      "\n",
      "\n",
      "Full stats files\n",
      "------------------------------------------------\n",
      "step 1: ./iptest_fastqs/s1_demultiplex_stats.txt\n",
      "step 2: ./iptest_edits/s2_rawedit_stats.txt\n",
      "step 3: ./iptest_clust_0.85/s3_cluster_stats.txt\n",
      "step 4: ./iptest_clust_0.85/s4_joint_estimate.txt\n",
      "step 5: None\n",
      "step 6: None\n",
      "step 7: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-iptest.txt -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Consensus base calls\n",
    "\n",
    "Step 5 uses the inferred error rate and heterozygosity to call the consensus of sequences within each cluster. Here we are identifying what we believe to be the real haplotypes at each locus within each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  loading Assembly: iptest\n",
      "  from saved path: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest.json\n",
      "  host compute node: [1 cores] on ubuntu\n",
      "\n",
      "  Step 5: Consensus base calling \n",
      "  Mean error  [0.00076 sd=0.00001]\n",
      "  Mean hetero [0.00192 sd=0.00012]\n",
      "  [####################] 100%  calculating depths    | 0:00:01  \n",
      "  [####################] 100%  chunking clusters     | 0:00:00  \n",
      "  [####################] 100%  consens calling       | 0:00:23  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-iptest.txt -s 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary stats of Assembly iptest\n",
      "------------------------------------------------\n",
      "      state  reads_raw  reads_passed_filter  clusters_total  clusters_hidepth  \\\n",
      "1A_0      5      19862                19862            1000              1000   \n",
      "1B_0      5      20043                20043            1000              1000   \n",
      "1C_0      5      20136                20136            1000              1000   \n",
      "1D_0      5      19966                19966            1000              1000   \n",
      "2E_0      5      20017                20017            1000              1000   \n",
      "2F_0      5      19933                19933            1000              1000   \n",
      "2G_0      5      20030                20030            1000              1000   \n",
      "2H_0      5      20199                20199            1000              1000   \n",
      "3I_0      5      19885                19885            1000              1000   \n",
      "3J_0      5      19822                19822            1000              1000   \n",
      "3K_0      5      19965                19965            1000              1000   \n",
      "3L_0      5      20008                20008            1000              1000   \n",
      "\n",
      "      hetero_est  error_est  reads_consens  \n",
      "1A_0    0.001824   0.000759           1000  \n",
      "1B_0    0.001908   0.000752           1000  \n",
      "1C_0    0.002084   0.000745           1000  \n",
      "1D_0    0.001803   0.000761           1000  \n",
      "2E_0    0.001830   0.000766           1000  \n",
      "2F_0    0.001996   0.000755           1000  \n",
      "2G_0    0.001940   0.000763           1000  \n",
      "2H_0    0.001747   0.000756           1000  \n",
      "3I_0    0.001807   0.000758           1000  \n",
      "3J_0    0.001931   0.000776           1000  \n",
      "3K_0    0.002092   0.000766           1000  \n",
      "3L_0    0.002042   0.000748           1000  \n",
      "\n",
      "\n",
      "Full stats files\n",
      "------------------------------------------------\n",
      "step 1: ./iptest_fastqs/s1_demultiplex_stats.txt\n",
      "step 2: ./iptest_edits/s2_rawedit_stats.txt\n",
      "step 3: ./iptest_clust_0.85/s3_cluster_stats.txt\n",
      "step 4: ./iptest_clust_0.85/s4_joint_estimate.txt\n",
      "step 5: ./iptest_consens/s5_consens_stats.txt\n",
      "step 6: None\n",
      "step 7: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Again we can ask for the results with the -r flag\n",
    "!ipyrad -p params-iptest.txt -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here the important information is the number of ``reads_consens``. This is the number of “good” reads within each sample that we’ll send on to the next step. As you’ll see in examples with empirical data, this is often a step where many reads are filtered out of the data set. If no reads were filtered, then the number of reads_consens should be equal to the number of clusters_hidepth.\n",
    "\n",
    "I think \"good\" reads here refers to what we'd think of as retained loci. Number of good consensus sequences = number of good loci?\n",
    "\n",
    "This step creates a new directory called ``./iptest_consens`` to store the consensus sequences for each sample. We can use our trusty head command to look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1A_0_0\r\n",
      "TGCAGCAAGATCACGGCGGACAGAACCGCCCCTTTTCTTGTTGCTGGTTAACTTCACGCCGTCATGGTTAGTGGTCAGGCTTTACAGGTCC\r\n",
      ">1A_0_1\r\n",
      "TGCAGACGTGATGGCTATCCATAGAGCGCCTTATTTGCGGGTACGTACACCCATCATGTGCCCCGAAGACTGGGTGATTTCGCCCGAGCGT\r\n",
      ">1A_0_2\r\n",
      "TGCAGGAGCGGTGCTACGTCGTGATGCCTTCACCCTCAATGTTAATAGCAGGTCAGGGCCTAATTTGATAATGACTAACCTGTAAACCTAC\r\n",
      ">1A_0_3\r\n",
      "TGCAGCACGAAGTTAACTTCAACCCTCGCCACTACTGCGTACAAAACGCGAGAGGTCTCCATGAGTGTCGCATCCGCTGTGGTGGTTACAT\r\n",
      ">1A_0_4\r\n",
      "TGCAGTGCTCCCGATATGCATGAACACTTGGAGGGAGGACTTCTCCGTGAGTTCAAGGCTCAGTCGGCAAGACGTCAATGAATATGCGGTC\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!gunzip -c iptest_consens/1A_0.consens.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all loci within each sample have been reduced to one consensus sequence. Heterozygous sites are represented by IUPAC ambiguity codes (find the K in sequence 1A_0_1), and all other sites are homozygous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Cluster across samples\n",
    "\n",
    "Step 6 clusters consensus sequences across samples. Now that we have good estimates for haplotypes within samples we can try to identify similar sequences at each locus between samples. We use the same clustering threshold as step 3 to identify sequences between samples that are probably sampled from the same locus, based on sequence similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  loading Assembly: iptest\n",
      "  from saved path: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest.json\n",
      "  host compute node: [1 cores] on ubuntu\n",
      "\n",
      "  Step 6: Clustering at 0.85 similarity across 12 samples\n",
      "  [####################] 100%  concat/shuffle input  | 0:00:01  \n",
      "  [####################] 100%  clustering across     | 0:00:00  \n",
      "  [####################] 100%  building clusters     | 0:00:00  \n",
      "  [####################] 100%  aligning clusters     | 0:00:08  \n",
      "  [####################] 100%  database indels       | 0:00:00  \n",
      "  [####################] 100%  indexing clusters     | 0:00:01  \n",
      "  [####################] 100%  building database     | 0:00:00  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-iptest.txt -s 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step differs from previous steps in that we are no longer applying a function to each Sample individually, but instead we apply it to all Samples collectively. Our end result is a map telling us which loci cluster together from which Samples. This output is stored as an HDF5 database (iptest_test.hdf5), which is not easily human readable. It contains the clustered sequence data, depth information, phased alleles, and other metadata. If you really want to see the contents of the database see the h5py cookbook recipe.\n",
    "\n",
    "There is no simple way to summarize the outcome of step 6, so the output of ipyrad -p params-iptest -r and the content of the ``./iptest_consens/s6_cluster_stats.txt`` stats file are uniquely uninteresting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Filter and write output files\n",
    "\n",
    "The final step is to filter the data and write output files in many convenient file formats. First we apply filters for maximum number of indels per locus, max heterozygosity per locus, max number of snps per locus, and minimum number of samples per locus. All these filters are configurable in the params file and you are encouraged to explore different settings, but the defaults are quite good and quite conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  loading Assembly: iptest\n",
      "  from saved path: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest.json\n",
      "  host compute node: [1 cores] on ubuntu\n",
      "\n",
      "  Step 7: Filter and write output files for 12 Samples\n",
      "  [####################] 100%  filtering loci        | 0:00:04  \n",
      "  [####################] 100%  building loci/stats   | 0:00:00  \n",
      "  [####################] 100%  building vcf file     | 0:00:03  \n",
      "  [####################] 100%  writing vcf file      | 0:00:00  \n",
      "  [####################] 100%  building arrays       | 0:00:00  \n",
      "  [####################] 100%  writing outfiles      | 0:00:00  \n",
      "  Outfiles written to: /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/iptest_outfiles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-iptest.txt -s 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new directory is created called iptest_outfiles. This directory contains all the output files specified in the params file. The default is to create all supported output files which include PHYLIP(.phy), NEXUS(.nex), EIGENSTRAT’s genotype format(.geno), STRUCTURE(.str), as well as many others. Explore some of these files below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final stats file\n",
    "\n",
    "The final stats output file contains a large number of statistics telling you why some loci were filtered from the data set, how many loci were recovered per sample, how many loci were shared among some number of samples, and how much variation is present in the data. Check out the results file. (Unclear from the tutorial how to access the stats file... going to poke around in the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "## The number of loci caught by each filter.\r\n",
      "## ipyrad API location: [assembly].stats_dfs.s7_filters\r\n",
      "\r\n",
      "                            total_filters  applied_order  retained_loci\r\n",
      "total_prefiltered_loci               1000              0           1000\r\n",
      "filtered_by_rm_duplicates               0              0           1000\r\n",
      "filtered_by_max_indels                  0              0           1000\r\n",
      "filtered_by_max_snps                    0              0           1000\r\n",
      "filtered_by_max_shared_het              0              0           1000\r\n",
      "filtered_by_min_sample                  0              0           1000\r\n",
      "filtered_by_max_alleles                 0              0           1000\r\n",
      "total_filtered_loci                  1000              0           1000\r\n",
      "\r\n",
      "\r\n",
      "## The number of loci recovered for each Sample.\r\n",
      "## ipyrad API location: [assembly].stats_dfs.s7_samples\r\n",
      "\r\n",
      "      sample_coverage\r\n",
      "1A_0             1000\r\n",
      "1B_0             1000\r\n",
      "1C_0             1000\r\n",
      "1D_0             1000\r\n",
      "2E_0             1000\r\n",
      "2F_0             1000\r\n",
      "2G_0             1000\r\n",
      "2H_0             1000\r\n",
      "3I_0             1000\r\n",
      "3J_0             1000\r\n",
      "3K_0             1000\r\n",
      "3L_0             1000\r\n",
      "\r\n",
      "\r\n",
      "## The number of loci for which N taxa have data.\r\n",
      "## ipyrad API location: [assembly].stats_dfs.s7_loci\r\n",
      "\r\n",
      "    locus_coverage  sum_coverage\r\n",
      "1                0             0\r\n",
      "2                0             0\r\n",
      "3                0             0\r\n",
      "4                0             0\r\n",
      "5                0             0\r\n",
      "6                0             0\r\n",
      "7                0             0\r\n",
      "8                0             0\r\n",
      "9                0             0\r\n",
      "10               0             0\r\n",
      "11               0             0\r\n",
      "12            1000          1000\r\n",
      "\r\n",
      "\r\n",
      "## The distribution of SNPs (var and pis) per locus.\r\n",
      "## var = Number of loci with n variable sites (pis + autapomorphies)\r\n",
      "## pis = Number of loci with n parsimony informative site (minor allele in >1 sample)\r\n",
      "## ipyrad API location: [assembly].stats_dfs.s7_snps\r\n",
      "\r\n",
      "    var  sum_var  pis  sum_pis\r\n",
      "0    16        0  331        0\r\n",
      "1    55       55  376      376\r\n",
      "2   106      267  208      792\r\n",
      "3   208      891   52      948\r\n",
      "4   198     1683   26     1052\r\n",
      "5   145     2408    4     1072\r\n",
      "6   124     3152    3     1090\r\n",
      "7    69     3635    0     1090\r\n",
      "8    50     4035    0     1090\r\n",
      "9    12     4143    0     1090\r\n",
      "10   10     4243    0     1090\r\n",
      "11    3     4276    0     1090\r\n",
      "12    3     4312    0     1090\r\n",
      "13    1     4325    0     1090\r\n",
      "\r\n",
      "\r\n",
      "## Final Sample stats summary\r\n",
      "\r\n",
      "      state  reads_raw  reads_passed_filter  clusters_total  clusters_hidepth  hetero_est  error_est  reads_consens  loci_in_assembly\r\n",
      "1A_0      7      19862                19862            1000              1000    0.001824   0.000759           1000              1000\r\n",
      "1B_0      7      20043                20043            1000              1000    0.001908   0.000752           1000              1000\r\n",
      "1C_0      7      20136                20136            1000              1000    0.002084   0.000745           1000              1000\r\n",
      "1D_0      7      19966                19966            1000              1000    0.001803   0.000761           1000              1000\r\n",
      "2E_0      7      20017                20017            1000              1000    0.001830   0.000766           1000              1000\r\n",
      "2F_0      7      19933                19933            1000              1000    0.001996   0.000755           1000              1000\r\n",
      "2G_0      7      20030                20030            1000              1000    0.001940   0.000763           1000              1000\r\n",
      "2H_0      7      20199                20199            1000              1000    0.001747   0.000756           1000              1000\r\n",
      "3I_0      7      19885                19885            1000              1000    0.001807   0.000758           1000              1000\r\n",
      "3J_0      7      19822                19822            1000              1000    0.001931   0.000776           1000              1000\r\n",
      "3K_0      7      19965                19965            1000              1000    0.002092   0.000766           1000              1000\r\n",
      "3L_0      7      20008                20008            1000              1000    0.002042   0.000748           1000              1000"
     ]
    }
   ],
   "source": [
    "# ha, I found it!\n",
    "!head -n 100 iptest_outfiles/iptest_stats.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the .loci output (this is ipyrad native internal format). Each locus is delineated by a pair of forward slashes //. Within each locus are all the reads from each sample that clustered together. The line containing the // also indicates the positions of SNPs in the sequence. See if you can spot the SNPs in the first locus. Many more output formats are available. See the section on output formats for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "1B_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "1C_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "1D_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "2E_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTACACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "2F_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTACACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "2G_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "2H_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTACACGTGGCAGGACCTGTTGGAAAAACACGCAGAGAGGA\r\n",
      "3I_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "3J_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "3K_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTATACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "3L_0     TTAGTTCTTAGACTATTCGTTAACTCGAGGCGAGTGCCCTAAGCGCTAAACGTGGCAGGACCTGTTGGAAAAACACGCAGAAAGGA\r\n",
      "//                                                       *                                -    |0|\r\n",
      "1A_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "1B_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "1C_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "1D_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGWTCT\r\n",
      "2E_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "2F_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACATGCCCCGGCCCGACC-ACTCTAACTCGATGTAGGAGTTCT\r\n",
      "2G_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "2H_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "3I_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "3J_0     TTGTCCATTTTCAAGTCAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n",
      "3K_0     TTGTCCATTTTCAAGTTAGTTAGCGAAAGACCAGTGTACTTACACTTGCCCCGGCCCGACCGACTCTAACTCGATGTAGGAGTTCT\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 24 iptest_outfiles/iptest.loci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the end of the tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning about branching assemblies\n",
    "\n",
    "From iPyrad's site on [Assembly Outline](http://ipyrad.readthedocs.io/outline.html#branching-workflow).\n",
    "\n",
    "The reason we separate assembly into distinct steps is to create a modular workflow that can be easily restarted if interrupted, and can be easily branched at different points to create assemblies under different combinations of parameter settings.\n",
    "\n",
    "If you want to run all steps at once, you make your params file and call:\n",
    "```\n",
    "ipyrad -p params-data1.txt -s 1234567\n",
    "```\n",
    "\n",
    "Branching is where you use the same output files from one step to move forward using multiple parameter sets. Branching does not create hard copies of existing data files, and so is not an “expensive” action in terms of disk space or time. We suggest it be used quite liberally whenever applying a new set of parameters. The code for branching is only a tad more complicated:\n",
    "\n",
    "```\n",
    "## create an initial Assembly and params file, here called 'data1'\n",
    ">>> ipyrad -n data1\n",
    "\n",
    "## edit the params file for data1 with your text editor\n",
    "## ... editing params-data1.txt\n",
    "\n",
    "## run steps 1-2 with the params file\n",
    ">>> ipyrad -p params-data1.txt -s 12\n",
    "\n",
    "## create a new branch of 'data1' before step3, here called 'data2'.\n",
    ">>> ipyrad -p params-data1.txt -b data2\n",
    "\n",
    "## edit the params file for data2 using a text editor\n",
    "## ... editing params-data2.txt\n",
    "\n",
    "## run steps 3-7 for both assemblies\n",
    ">>> ipyrad -p params-data1.txt -s 34567\n",
    ">>> ipyrad -p params-data2.txt -s 34567\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python API\n",
    "\n",
    "Apparently I don't have a full understanding of what an API is, but lookie here, you can run iPyrad within Python. That sounds like it could be useful at times!\n",
    "\n",
    "```\n",
    "## import ipyrad\n",
    "import ipyrad as ip\n",
    "\n",
    "## create an Assembly and modify some parameter settings\n",
    "data1 = ip.Assembly(\"data1\")\n",
    "data1.set_params(\"project_dir\", \"example\")\n",
    "data1.set_params(\"raw_fastq_path\", \"data/*.fastq\")\n",
    "data1.set_params(\"barcodes_path\", \"barcodes.txt\")\n",
    "\n",
    "## run steps 1-2\n",
    "data1.run(\"12\")\n",
    "\n",
    "## create a new branch of this Assembly named data2\n",
    "## and change some parameter settings\n",
    "data2 = data1.branch(\"data2\")\n",
    "data2.set_params(\"clust_threshold\", 0.90)\n",
    "\n",
    "## run steps 3-7 for the two Assemblies\n",
    "data1.run(\"34567\")\n",
    "data2.run(\"34567\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
