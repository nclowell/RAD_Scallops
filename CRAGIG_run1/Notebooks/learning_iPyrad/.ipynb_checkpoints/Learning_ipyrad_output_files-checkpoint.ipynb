{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning ipyrad output files\n",
    "\n",
    "**20170517**\n",
    "\n",
    "I want to get the hang of navigating and plotting things from the output files in ipyrad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUN1_py\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUN1_py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I can get the summary stats and paths to all the output files using the ``-r`` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary stats of Assembly cragig002\n",
      "------------------------------------------------\n",
      "         state  reads_raw  reads_passed_filter  clusters_total  \\\n",
      "FG001        6    4496623              4496623           28719   \n",
      "FG009        6    5828500              5828500           31799   \n",
      "FG100_B      6    4191123              4191123           27072   \n",
      "FG102_B      6    3757306              3757306           32437   \n",
      "FG205        6    4762949              4762949           28809   \n",
      "FG212        6    4163068              4163068            1568   \n",
      "Q314         6    3797205              3797205           32843   \n",
      "Q324         6    4203350              4203350           47166   \n",
      "Q330         6    3683576              3683576           63309   \n",
      "Q339         6    6057345              6057345          142327   \n",
      "\n",
      "         clusters_hidepth  hetero_est  error_est  reads_consens  \n",
      "FG001               18878    0.021602   0.002395          16813  \n",
      "FG009               19670    0.021421   0.002188          17458  \n",
      "FG100_B             18151    0.022895   0.002237          16048  \n",
      "FG102_B             18407    0.021645   0.001982          16410  \n",
      "FG205               18786    0.022490   0.002163          16665  \n",
      "FG212                1550    0.018168   0.001776           1405  \n",
      "Q314                19094    0.023120   0.002253          17022  \n",
      "Q324                22765    0.026930   0.003639          19433  \n",
      "Q330                30700    0.015597   0.002452          28035  \n",
      "Q339                45676    0.015476   0.002377          40805  \n",
      "\n",
      "\n",
      "Full stats files\n",
      "------------------------------------------------\n",
      "step 1: ./cragig001_s1_demultiplex_stats.txt\n",
      "step 2: ./cragig001_edits/s2_rawedit_stats.txt\n",
      "step 3: ./cragig002_clust_0.82/s3_cluster_stats.txt\n",
      "step 4: ./cragig002_clust_0.82/s4_joint_estimate.txt\n",
      "step 5: ./cragig002_consens/s5_consens_stats.txt\n",
      "step 6: ./cragig002_consens/s6_cluster_stats.txt\n",
      "step 7: ./cragig002_outfiles/cragig002_stats.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-cragig002.txt -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Clustering is one of the most important and sensitive steps. So it's worth understanding what's in the s3_cluster_stats.txt files. I talked to Katherine on the phone to help make sense of the headers, because the documentation is not extremely thorough (the cost of the writers making everything sleek and simple!). So, here's the file:\n",
    "\n",
    "![img](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_run1/Notebooks/images_for_notebooks/ex_cluster_stats_file.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote a script that produces scatter plots comparing different output stats. Script lives [here](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_run1/Scripts/data_exploration/ipyrad_clust_stats_plots.py). It allows optional flags so you can specify which plots you want made. \n",
    "\n",
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/SHARED_FOLDER/Git_repo/CRAGIG_run1/Scripts/data_exploration\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/SHARED_FOLDER/Git_repo/CRAGIG_run1/Scripts/data_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipyrad_clust_stats_plots.py [-h] -a ASSEMBLY -i INFILE [-o OUTDIR] [-x]\r\n",
      "                                   [-y] [-z]\r\n",
      "\r\n",
      "Produces plots from ipyrad cluster stats output file\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -a ASSEMBLY, --assembly ASSEMBLY\r\n",
      "                        Assembly name\r\n",
      "  -i INFILE, --infile INFILE\r\n",
      "                        Path to cluster stats output file from ipyrad\r\n",
      "  -o OUTDIR, --outdir OUTDIR\r\n",
      "                        Path to directory for output files\r\n",
      "  -x                    Make scatter plot showing total number of clusters vs\r\n",
      "                        number of clusters filtered for depth\r\n",
      "  -y                    Make plot showing average depth with majority rule vs\r\n",
      "                        number of clusters filtered for depth\r\n",
      "  -z                    Make plot showing standard deviation of read depth\r\n",
      "                        with majority rule vs number of clusters filtered for\r\n",
      "                        depth\r\n"
     ]
    }
   ],
   "source": [
    "!python ipyrad_clust_stats_plots.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots look like this:\n",
    "\n",
    "![img](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_run1/Notebooks/images_for_notebooks/avg_rd_mj_v_filt_clusts_20170517.png?raw=true)\n",
    "![img](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_run1/Notebooks/images_for_notebooks/sd_rd_mj_v_filt_clusts_20170517.png?raw=true)\n",
    "![img](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_run1/Notebooks/images_for_notebooks/tot_clusts_v_filt_clusts_20170517.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Output Files\n",
    "\n",
    "#### .loci\n",
    "\n",
    ".alleles.loci files are probably the ones I will use to build a Genepop and run stats on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUN1_py\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUN1_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_alleles = open(\"cragig001_outfiles/cragig001.test.alleles\", \"r\")\n",
    "test_lines = test_alleles.readlines()\n",
    "test_alleles.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of characters leading to sequence, will need for getting SNP positions out of // lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_line_list = test_lines[0].strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG001_0\n",
      "TCTCCCTGACATCAGGGGGTTTCCTTAGGCAGCTCGAAGGTCCACCTAAAACCAAATTAAACCAACTTTTCCTGGTAGATAATTTGTCGAGGCTAATTTCCTCAGGTGTAATAATTGGTTAGGAGTAACGCTATGA\n"
     ]
    }
   ],
   "source": [
    "print test_line_list[0]\n",
    "print test_line_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "len_line = len(test_lines[0].strip())\n",
    "print len_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "len_sample = len(test_line_list[0])\n",
    "print len_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "len_seq = len(test_line_list[1])\n",
    "print len_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "num_spaces = len_line - len_sample - len_seq\n",
    "print num_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "start_ind_zb = len_sample + num_spaces\n",
    "print start_ind_zb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCT\n"
     ]
    }
   ],
   "source": [
    "# test starting index is right\n",
    "print test_lines[0][14:17] # should be TCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find(s, ch):\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get number of loci and sorted SNP positions\n",
    "count = 0\n",
    "positions = {}\n",
    "for line in test_lines:\n",
    "    if line[0:2] == \"//\":\n",
    "        count += 1\n",
    "        snp_pos_list = []\n",
    "        indeces_hash = find(line,'-')\n",
    "        indeces_hash[:] = [x - start_ind_zb for x in indeces_hash]\n",
    "        indeces_ast = find(line, '*')\n",
    "        indeces_ast[:] = [x - start_ind_zb for x in indeces_ast]\n",
    "        snp_pos_list = indeces_hash + indeces_ast\n",
    "        snp_pos_list.sort()\n",
    "        tagname = int(line.strip().split()[-1].replace(\"|\", \"\").replace(\"-\", \"\").replace(\"*\", \"\"))\n",
    "        positions[tagname] = snp_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 12, 16, 18, 27, 34, 36, 38, 47, 84, 119]\n"
     ]
    }
   ],
   "source": [
    "print positions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting to Genepop file\n",
    "\n",
    "**20170519**\n",
    "\n",
    "Katherine said she uses PGDSpider to convert ipyrad.VCF to Genepop. Let's see if I can figure that out. Yikes - it keeps crapping out with an error that says ``ERROR 10:37:21 - input file error at line: 1342``, with a different line for each VCF file. Katherine mentioned that at some point ipyrad spit out weird VCF files. So until then, it might be worth trying to make a genepop from the alleles loci files that have both alleles for each RAD tag for each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
